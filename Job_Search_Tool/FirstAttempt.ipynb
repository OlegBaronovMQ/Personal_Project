{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4c09e26-890c-46b2-889b-2a53d8300e73",
   "metadata": {},
   "source": [
    "# Job Search Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8638c5b-9690-4db1-886e-f43b831330c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from: https://www.seek.com.au/Junior-data-analyst-jobs/in-Newington-NSW-2127?daterange=7&distance=25\n",
      "Fetching data from: https://www.seek.com.au/Junior-data-analyst-jobs/in-Newington-NSW-2127?daterange=7&distance=25&page=2\n",
      "Fetching data from: https://www.seek.com.au/Junior-data-analyst-jobs/in-Newington-NSW-2127?daterange=7&distance=25&page=3\n",
      "Fetching data from: https://www.seek.com.au/Junior-data-analyst-jobs/in-Newington-NSW-2127?daterange=7&distance=25&page=4\n",
      "Fetching data from: https://www.seek.com.au/Junior-data-analyst-jobs/in-Newington-NSW-2127?daterange=7&distance=25&page=5\n",
      "Fetching data from: https://www.seek.com.au/Junior-data-analyst-jobs/in-Newington-NSW-2127?daterange=7&distance=25&page=6\n",
      "No next page found.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract(baseurl):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    response = requests.get(baseurl, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        return soup\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def get_job_summary(soup, i):\n",
    "    if soup is None:\n",
    "        return [], i\n",
    "    \n",
    "    joblist = []\n",
    "    divs = soup.find_all('article', {'data-automation': \"normalJob\"})\n",
    "    for item in divs:\n",
    "        i += 1\n",
    "        jobD = item.find('span', {'data-automation': 'jobShortDescription'})\n",
    "        jobD = jobD.text if jobD else 'NA'\n",
    "\n",
    "        job_title = item.find('a', {'data-automation': 'jobTitle'})\n",
    "        href = job_title.get('href') if job_title else ''\n",
    "        job_title = job_title.text if job_title else 'NA'\n",
    "\n",
    "        next_page_url = 'https://www.seek.com.au' + href\n",
    "        \n",
    "        # Fetch long description from detailed page\n",
    "        details_soup = extract(next_page_url)\n",
    "        jobLongD = 'NA'\n",
    "        if details_soup:\n",
    "            jobLongD_div = details_soup.find('div', {'class': 'xvu5580 _1o93qk60'})\n",
    "            if jobLongD_div:\n",
    "                jobLongD_parts = []\n",
    "                for element in jobLongD_div.find_all(['p', 'ul', 'li'], recursive=True):\n",
    "                    text = element.get_text(separator='\\n', strip=True)\n",
    "                    if text:\n",
    "                        jobLongD_parts.append(text)\n",
    "                jobLongD = '\\n'.join(jobLongD_parts)\n",
    "\n",
    "        job_salary = item.find('span', {'data-automation': 'jobSalary'})\n",
    "        job_salary = job_salary.text if job_salary else 'NA'\n",
    "\n",
    "        job_company = item.find('a', {'data-automation': 'jobCompany'})\n",
    "        job_company = job_company.text if job_company else 'NA'\n",
    "\n",
    "        job_loc = item.find('a', {'data-automation': 'jobLocation'})\n",
    "        job_loc = job_loc.text if job_loc else 'NA'\n",
    "\n",
    "        job_clas = item.find('a', {'data-automation': 'jobClassification'})\n",
    "        job_clas = job_clas.text if job_clas else 'NA'\n",
    "\n",
    "        date = item.find('span', {\"data-automation\": \"jobListingDate\"})\n",
    "        date = date.text if date else 'NA'\n",
    "\n",
    "        job = {\n",
    "            'jobID': i,\n",
    "            'description': jobD,\n",
    "            'Long_Description': jobLongD,\n",
    "            'title': job_title,\n",
    "            'salary': job_salary,\n",
    "            'company': job_company,\n",
    "            'location': job_loc,\n",
    "            'class': job_clas,\n",
    "            'days_before': date,\n",
    "            'link': next_page_url\n",
    "        }\n",
    "        joblist.append(job)\n",
    "    return joblist, i\n",
    "\n",
    "def get_next_page_url(soup):\n",
    "    next_button = soup.find('a', {'aria-label': 'Next'})\n",
    "    if next_button:\n",
    "        next_page_url = next_button.get('href')\n",
    "        if not next_page_url.startswith('http'):\n",
    "            next_page_url = 'https://www.seek.com.au' + next_page_url\n",
    "        return next_page_url\n",
    "    print(\"No next page found.\")\n",
    "    return None\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    return text\n",
    "\n",
    "def match_keywords(description, keywords):\n",
    "    score = defaultdict(int)\n",
    "    for category, words in keywords.items():\n",
    "        for word in words:\n",
    "            if word in description:\n",
    "                score[category] += 1\n",
    "    return score\n",
    "\n",
    "# Define your keywords\n",
    "keywords = {\n",
    "    'must_have': ['data science', 'python', 'sql', 'bachelor', 'data engineering'],\n",
    "    'nice_to_have': ['student', 'tableau', 'java', 'ai', \"above 80\", 'distinction', 'ETL'],\n",
    "    'time_relevant': ['2025', 'february', 'january'],\n",
    "    'experience_relevant': [\"1-2 years\", \"no experience\", \"2 years\", \"1 year\"]\n",
    "}\n",
    "\n",
    "# Main function to run the scraping and processing\n",
    "def main():\n",
    "    joblist = []\n",
    "    baseurl = \"https://www.seek.com.au/Junior-data-analyst-jobs/in-Newington-NSW-2127?daterange=7&distance=25\"\n",
    "    i = 0\n",
    "\n",
    "    while baseurl:\n",
    "        print(f'Fetching data from: {baseurl}')\n",
    "        soup = extract(baseurl)\n",
    "        jobs, i = get_job_summary(soup, i)\n",
    "        joblist.extend(jobs)\n",
    "        baseurl = get_next_page_url(soup)\n",
    "        sleep(1)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(joblist)\n",
    "\n",
    "    # Preprocess the 'Long_Description' and pair with 'jobID'\n",
    "    df['Long_Description'] = df['Long_Description'].apply(preprocess)\n",
    "\n",
    "    # Evaluate job descriptions and add scores to the DataFrame\n",
    "    df['scores'] = df['Long_Description'].apply(lambda desc: match_keywords(desc, keywords))\n",
    "\n",
    "    # Rank the jobs based on the scores\n",
    "    df['rank'] = df['scores'].apply(lambda x: (x['must_have'], x['nice_to_have'], x['time_relevant'], x['experience_relevant']))\n",
    "    df_ranked = df.sort_values(by='rank', ascending=False)\n",
    "    df_result = df_ranked.drop(['scores', 'Long_Description'], axis=1)\n",
    "\n",
    "    # Save the ranked DataFrame to CSV\n",
    "    df_result.to_csv('ranked_report.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2326bc0-5cc2-4ac5-85e0-424dcbcc4b50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
